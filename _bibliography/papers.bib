@inproceedings{gu2024mllmguard,
  title     = {MLLMGUARD: a multi-dimensional safety evaluation suite for multimodal large language models},
  author    = {Gu, Tianle and Zhou, Zeyang and Huang, Kexin and Liang, Dandan and Wang, Yixu and Zhao, Haiquan and Yao, Yuanqi and Qiao, Xingge and Wang, Keqing and Yang, Yujiu and others},
  booktitle = {Proceedings of the 38th International Conference on Neural Information Processing Systems},
  pages     = {7256--7295},
  year      = {2024},
  tag       = {NeurIPS},
  level     = {A},
  selected  = {true},
  pdf       = {https://arxiv.org/pdf/2406.07594},
  review    = {https://openreview.net/forum?id=k4tuZmvSnl&referrer=%5Bthe%20profile%20of%20Yujiu%20Yang%5D(%2Fprofile%3Fid%3D~Yujiu_Yang2)},
  dataset   = {https://huggingface.co/datasets/Carol0110/MLLMGuard},
  url       = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:ZeXyd9-uunAC}
}

@inproceedings{gu-etal-2025-evasion,
    title = "From Evasion to Concealment: Stealthy Knowledge Unlearning for {LLM}s",
    author = "Gu, Tianle  and
      Huang, Kexin  and
      Luo, Ruilin  and
      Yao, Yuanqi  and
      Chen, Xiuying  and
      Yang, Yujiu  and
      Teng, Yan  and
      Wang, Yingchun",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-acl.535/",
    scholar_url = "https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:_FxGoFyzp5QC",
    google_scholar_id = {_FxGoFyzp5QC},
    pdf = "https://aclanthology.org/2025.findings-acl.535.pdf",
    pages = "10261--10279",
    ISBN = "979-8-89176-256-5",
    tag       = {ACL\n(Findings)},
    level     = {A},
    selected  = {true},
    abstract = "LLM Unlearning plays a crucial role in removing sensitive information from language models to mitigate potential misuse. However, previous approaches often treat nonsensical responses or template-based refusals (e.g., ``Sorry, I cannot answer.'') as the unlearning target, which can give the impression of deliberate information suppression, making the process even more vulnerable to attacks and jailbreaks. Moreover, most methods rely on auxiliary models or retaining datasets, which adds complexity to the unlearning process. To address these challenges, we propose MEOW, a streamlined and stealthy unlearning method that eliminates the need for auxiliary models or retaining data while avoiding leakage through its innovative use of inverted facts. These inverted facts are generated by an offline LLM and serve as fine-tuning labels. Meanwhile, we introduce MEMO, a novel metric that measures the model{'}s memorization, to select optimal fine-tuning targets. The use of inverted facts not only maintains the covert nature of the model but also ensures that sensitive information is effectively forgotten without revealing the target data. Evaluated on the ToFU Knowledge Unlearning dataset using Llama2-7B-Chat and Phi-1.5, MEOW outperforms baselines in forgetting quality while preserving model utility. MEOW also maintains strong performance across NLU and NLG tasks and demonstrates superior resilience to attacks, validated via the Min-K{\%} membership inference method."
}
@article{wang2025morphmark,
  title              = {Morphmark: Flexible adaptive watermarking for large language models},
  author             = {Wang, Zongqi and Gu, Tianle and Wu, Baoyuan and Yang, Yujiu},
  journal            = {arXiv preprint arXiv:2505.11541},
  year               = {2025},
  scholar_url        = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:QIV2ME_5wuYC},
  google_scholar_id  = {QIV2ME_5wuYC},
  tag                = {ACL},
  level              = {A},
  first_author_count = {2},
  selected           = {true}
}

@article{gu2025invisible,
  title   = {Invisible Entropy: Towards Safe and Efficient Low-Entropy LLM Watermarking},
  author  = {Gu, Tianle and Wang, Zongqi and Huang, Kexin and Yao, Yuanqi and Zhang, Xiangliang and Yang, Yujiu and Chen, Xiuying},
  journal = {arXiv preprint arXiv:2505.14112},
  year    = {2025},
  scholar_url = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:eQOLeE2rZwMC},
  google_scholar_id = {eQOLeE2rZwMC},
  level   = {B},
  tag     = {EMNLP\n(Oral)},
  selected = {true}
}

@inproceedings{wang2025honeypotnet,
  title     = {HoneypotNet: Backdoor attacks against model extraction},
  author    = {Wang, Yixu and Gu, Tianle and Teng, Yan and Wang, Yingchun and Ma, Xingjun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {39},
  number    = {8},
  pages     = {8087--8095},
  year      = {2025},
  scholar_url = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:UeHWp8X0CEIC},
  google_scholar_id = {UeHWp8X0CEIC},
  level     = {A},
  tag       = {AAAI},
  selected  = {true}
}

@article{luo2024chain,
  title={Chain of history: Learning and forecasting with llms for temporal knowledge graph completion},
  author={Luo, Ruilin and Gu, Tianle and Li, Haoling and Li, Junzhe and Lin, Zicheng and Li, Jiayi and Yang, Yujiu},
  journal={arXiv preprint arXiv:2401.06072},
  year={2024},
  scholar_url={https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:Wp0gIr-vW9MC},
  google_scholar_id={Wp0gIr-vW9MC},
  tag={arXiv},
  level={N},
}
