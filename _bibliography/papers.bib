@inproceedings{gu2024mllmguard,
  title     = {MLLMGUARD: a multi-dimensional safety evaluation suite for multimodal large language models},
  author    = {Gu, Tianle and Zhou, Zeyang and Huang, Kexin and Liang, Dandan and Wang, Yixu and Zhao, Haiquan and Yao, Yuanqi and Qiao, Xingge and Wang, Keqing and Yang, Yujiu and others},
  booktitle = {Proceedings of the 38th International Conference on Neural Information Processing Systems},
  pages     = {7256--7295},
  year      = {2024},
  tag       = {NeurIPS},
  level     = {A},
  selected  = {true},
  abstract  = {We introduce MLLMGuard, a multi-dimensional safety evaluation suite for multimodal large language models. The framework covers diverse risk categories with bilingual data, standardized inference tooling, and both manual and automatic evaluation protocols. We further train a lightweight evaluator (GuardRank) on human annotations to enable scalable and reproducible scoring. Experiments on closed-source and open-source MLLMs show substantial safety differences across dimensions and reveal gaps not captured by existing single-axis benchmarks.},
  pdf       = {https://arxiv.org/pdf/2406.07594},
  review    = {https://openreview.net/forum?id=k4tuZmvSnl&referrer=%5Bthe%20profile%20of%20Yujiu%20Yang%5D(%2Fprofile%3Fid%3D~Yujiu_Yang2)},
  dataset   = {https://huggingface.co/datasets/Carol0110/MLLMGuard},
  url       = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:ZeXyd9-uunAC}
}

@inproceedings{gu-etal-2025-evasion,
    title = "From Evasion to Concealment: Stealthy Knowledge Unlearning for {LLM}s",
    author = "Gu, Tianle  and
      Huang, Kexin  and
      Luo, Ruilin  and
      Yao, Yuanqi  and
      Chen, Xiuying  and
      Yang, Yujiu  and
      Teng, Yan  and
      Wang, Yingchun",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-acl.535/",
    scholar_url = "https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:_FxGoFyzp5QC",
    google_scholar_id = {_FxGoFyzp5QC},
    pdf = "https://aclanthology.org/2025.findings-acl.535.pdf",
    github = "https://github.com/Carol-gutianle/MEOW",
    pages = "10261--10279",
    ISBN = "979-8-89176-256-5",
    tag       = {ACL\n(Findings)},
    level     = {A},
    selected  = {true},
    abstract = "LLM Unlearning plays a crucial role in removing sensitive information from language models to mitigate potential misuse. However, previous approaches often treat nonsensical responses or template-based refusals (e.g., ``Sorry, I cannot answer.'') as the unlearning target, which can give the impression of deliberate information suppression, making the process even more vulnerable to attacks and jailbreaks. Moreover, most methods rely on auxiliary models or retaining datasets, which adds complexity to the unlearning process. To address these challenges, we propose MEOW, a streamlined and stealthy unlearning method that eliminates the need for auxiliary models or retaining data while avoiding leakage through its innovative use of inverted facts. These inverted facts are generated by an offline LLM and serve as fine-tuning labels. Meanwhile, we introduce MEMO, a novel metric that measures the model{'}s memorization, to select optimal fine-tuning targets. The use of inverted facts not only maintains the covert nature of the model but also ensures that sensitive information is effectively forgotten without revealing the target data. Evaluated on the ToFU Knowledge Unlearning dataset using Llama2-7B-Chat and Phi-1.5, MEOW outperforms baselines in forgetting quality while preserving model utility. MEOW also maintains strong performance across NLU and NLG tasks and demonstrates superior resilience to attacks, validated via the Min-K{\%} membership inference method."
}
@article{wang2025morphmark,
  title              = {Morphmark: Flexible adaptive watermarking for large language models},
  author             = {Wang, Zongqi and Gu, Tianle and Wu, Baoyuan and Yang, Yujiu},
  journal            = {arXiv preprint arXiv:2505.11541},
  year               = {2025},
  abstract           = {This paper studies the effectiveness-quality trade-off in red-green list watermarking for LLM text generation. It formulates watermarking as a multi-objective optimization problem and identifies a key factor behind this dilemma. Based on the analysis, MorphMark is proposed as an adaptive method that dynamically adjusts watermark strength instead of using a fixed hyperparameter. The method is model-agnostic and model-free, making deployment easier across rapidly evolving models. Experiments show improved balance between watermark detectability and text quality, while also providing strong efficiency and flexibility.},
  scholar_url        = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:QIV2ME_5wuYC},
  google_scholar_id  = {QIV2ME_5wuYC},
  tag                = {ACL},
  level              = {A},
  first_author_count = {2},
  selected           = {true}
}

@article{gu2025invisible,
  title   = {Invisible Entropy: Towards Safe and Efficient Low-Entropy LLM Watermarking},
  author  = {Gu, Tianle and Wang, Zongqi and Huang, Kexin and Yao, Yuanqi and Zhang, Xiangliang and Yang, Yujiu and Chen, Xiuying},
  journal = {arXiv preprint arXiv:2505.14112},
  year    = {2025},
  scholar_url = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:eQOLeE2rZwMC},
  google_scholar_id = {eQOLeE2rZwMC},
  video   = {https://us06web.zoom.us/rec/play/FzjzZiyV_Z0m_87lBEEddOIwg21Tb5nBNoBi-94UZQK27M5nmpgakDUMJgpOzZsIMDkk2ib5I5c6_0k.MPrCH3D-XNczVqMf?eagerLoadZvaPages=sidemenu.billing.plan_management&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&startTime=1762481665000&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2FDnaVc2Gu-Wjqp9yhj1hdNWXovkRX2m7jAUp0qdjrbnVCijUNYa7nPaQqPwhlPRMd.mrntHZ1wGoLEbM6H%3FstartTime%3D1762481665000},
  level   = {B},
  tag     = {EMNLP\n(Oral)},
  abstract = {We present Invisible Entropy, a safe and efficient low-entropy watermarking paradigm for large language models. The method improves robustness and detectability while preserving text quality under practical decoding settings. It is designed to reduce deployment overhead and maintain compatibility with modern LLM generation pipelines. Extensive experiments show favorable trade-offs against prior watermarking methods across quality, security, and efficiency metrics.},
  selected = {true}
}

@inproceedings{wang2025honeypotnet,
  title     = {HoneypotNet: Backdoor attacks against model extraction},
  author    = {Wang, Yixu and Gu, Tianle and Teng, Yan and Wang, Yingchun and Ma, Xingjun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {39},
  number    = {8},
  pages     = {8087--8095},
  year      = {2025},
  scholar_url = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:UeHWp8X0CEIC},
  google_scholar_id = {UeHWp8X0CEIC},
  abstract = {We study model extraction under adversarial settings and propose HoneypotNet, a backdoor-based attack strategy against extraction pipelines. The method injects stealthy triggers that remain latent during normal usage but induce targeted behavior in extracted surrogate models. We analyze transferability and attack success under different query budgets and defense settings. Results show that extraction systems can inherit hidden vulnerabilities, motivating stronger auditing and robust defense mechanisms.},
  level     = {A},
  tag       = {AAAI}
}

@article{luo2024chain,
  title={Chain of history: Learning and forecasting with llms for temporal knowledge graph completion},
  author={Luo, Ruilin and Gu, Tianle and Li, Haoling and Li, Junzhe and Lin, Zicheng and Li, Jiayi and Yang, Yujiu},
  journal={arXiv preprint arXiv:2401.06072},
  year={2024},
  scholar_url={https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:Wp0gIr-vW9MC},
  google_scholar_id={Wp0gIr-vW9MC},
  abstract={We propose Chain of History, an LLM-based framework for temporal knowledge graph completion that jointly models historical evolution and future forecasting. The approach leverages sequential temporal context to improve reasoning over dynamic entities and relations. It supports both interpolation and extrapolation settings and integrates naturally with large language model priors. Experiments on benchmark temporal KGs demonstrate competitive or superior performance with strong generalization across time horizons.},
  tag={arXiv},
  level={N},
}

@inproceedings{chen2025benchmarking,
  title             = {Benchmarking large language models under data contamination: A survey from static to dynamic evaluation},
  author            = {Chen, Simin and Chen, Yiming and Li, Zexin and Jiang, Yifan and Wan, Zhongwei and He, Yixin and Ran, Dezhi and Gu, Tianle and Li, Haizhou and Xie, Tao and others},
  booktitle         = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  pages             = {10091--10109},
  year              = {2025},
  scholar_url       = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:kNdYIx-mwKoC},
  google_scholar_id = {kNdYIx-mwKoC},
  tag               = {EMNLP},
  level             = {B},
  selected          = {true}
}

@article{shanghai2025lab,
  title   = {Lab. Safework-r1: Coevolving safety and intelligence under the ai-45â—¦ law},
  author  = {Shanghai, AI},
  journal = {arXiv preprint arXiv:2507.18576},
  year    = {2025}
}

@inproceedings{luo2025fair,
  title     = {Fair Text-Attributed Graph Representation Learning},
  author    = {Luo, Ruilin and Gu, Tianle and Wang, Lin and Zhou, Yunfeng and Jiang, Songtao and Wang, Lei and Yang, Yujiu},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2025},
  year      = {2025},
  scholar_url = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&cstart=20&pagesize=80&citation_for_view=wlW9_7QAAAAJ:9ZlFYXVOiuMC},
  google_scholar_id = {9ZlFYXVOiuMC},
  pdf       = {https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.773.pdf},
  tag       = {EMNLP\n(Findings)},
  level     = {B}
}

@inproceedings{zhao-etal-2024-esc,
  title = "{ESC}-Eval: Evaluating Emotion Support Conversations in Large Language Models",
  author = "Zhao, Haiquan  and
    Li, Lingyu  and
    Chen, Shisong  and
    Kong, Shuqi  and
    Wang, Jiaan  and
    Huang, Kexin  and
    Gu, Tianle  and
    Wang, Yixu  and
    Wang, Jian  and
    Dandan, Liang  and
    Li, Zhixu  and
    Teng, Yan  and
    Xiao, Yanghua  and
    Wang, Yingchun",
  editor = "Al-Onaizan, Yaser  and
    Bansal, Mohit  and
    Chen, Yun-Nung",
  booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
  month = nov,
  year = "2024",
  address = "Miami, Florida, USA",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2024.emnlp-main.883/",
  doi = "10.18653/v1/2024.emnlp-main.883",
  pages = "15785--15810",
  abstract = "Emotion Support Conversation (ESC) is a crucial application, which aims to reduce human stress, offer emotional guidance, and ultimately enhance human mental and physical well-being. With the advancement of Large Language Models (LLMs), many researchers have employed LLMs as the ESC models. However, the evaluation of these LLM-based ESCs remains uncertain. In detail, we first re-organize 2,801 role-playing cards from seven existing datasets to define the roles of the role-playing agent. Second, we train a specific role-playing model called ESC-Role which behaves more like a confused person than GPT-4. Third, through ESC-Role and organized role cards, we systematically conduct experiments using 14 LLMs as the ESC models, including general AI-assistant LLMs (e.g., ChatGPT) and ESC-oriented LLMs (e.g., ExTES-Llama). We conduct comprehensive human annotations on interactive multi-turn dialogues of different ESC models. The results show that ESC-oriented LLMs exhibit superior ESC abilities compared to general AI-assistant LLMs, but there is still a gap behind human performance. Moreover, to automate the scoring process for future ESC models, we developed ESC-RANK, which trained on the annotated data, achieving a scoring performance surpassing 35 points of GPT-4.",
  scholar_url = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&pagesize=80&citation_for_view=wlW9_7QAAAAJ:2osOgNQ5qMEC},
  google_scholar_id = {2osOgNQ5qMEC},
  pdf = {https://aclanthology.org/2024.emnlp-main.883.pdf},
  tag = {EMNLP},
  level = {B}
}

@article{wang2026openrt,
  title             = {OpenRT: An Open-Source Red Teaming Framework for Multimodal LLMs},
  author            = {Wang, Xin and Chen, Yunhao and Li, Juncheng and Wang, Yixu and Yao, Yang and Gu, Tianle and Li, Jie and Teng, Yan and Ma, Xingjun and Wang, Yingchun and others},
  journal           = {arXiv preprint arXiv:2601.01592},
  year              = {2026},
  scholar_url       = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:YOwf2qJgpHMC},
  google_scholar_id = {YOwf2qJgpHMC},
  github            = {https://github.com/AI45Lab/OpenRT},
  tag               = {Technical\nReport},
  level             = {N}
}

@article{ning2025linguasafe,
  title             = {Linguasafe: A comprehensive multilingual safety benchmark for large language models},
  author            = {Ning, Zhiyuan and Gu, Tianle and Song, Jiaxin and Hong, Shixin and Li, Lingyu and Liu, Huacan and Li, Jie and Wang, Yixu and Lingyu, Meng and Teng, Yan and others},
  journal           = {arXiv preprint arXiv:2508.12733},
  year              = {2025},
  scholar_url       = {https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:5nxA0vEk-isC},
  google_scholar_id = {5nxA0vEk-isC},
  tag               = {arXiv},
  level             = {N}
}
