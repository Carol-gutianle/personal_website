cv:
  name: Tianle Gu
  label: LLM Safety Researcher
  email: gtl23@mails.tsinghua.edu.cn
  website: https://github.com/Carol-gutianle
  summary: Focused on LLM safety, alignment, and robust evaluation.

  sections:
    Education:
      - institution: Tsinghua University
        area: Electronic Information
        studyType: M.Eng.
        start_date: 2023
        end_date: 2026
        score: "GPA: 3.87/4.0"
        highlights:
          - "Supervised by [Prof. Yujiu Yang](https://scholar.google.com/citations?user=4gH3sxsAAAAJ), National Scholarship * 1"

      - institution: Hunan University
        area: Computer Science and Technology
        studyType: B.Eng.
        start_date: 2019
        end_date: 2023
        score: "GPA: 3.83/4.0 (Top 2%)"
        highlights:
          - "National Scholarship * 2"

    Publications:
      - title: "**Tianle Gu**, Zeyang Zhou, Kexin Huang, et al. MLLMGuard: A Multi-dimensional Safety Evaluation Suite for Multimodal Large Language Models"
        publisher: "Accepted by NeurIPS 2024"
        url: "https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=wlW9_7QAAAAJ&citation_for_view=wlW9_7QAAAAJ:ZeXyd9-uunAC"
        summary: "We designed a multi-dimensional safety benchmark for MLLMs, including bilingual data, an inference toolkit, and a lightweight automatic evaluator."

      - title: "**Tianle Gu, Zongqi Wang**, Kexin Huang, et al. Invisible Entropy: A Safe and Efficient Paradigm for Low-entropy Watermarking"
        publisher: "ArXiv; Accepted by EMNLP Main Conference (Oral)"
        url: "https://arxiv.org/abs/2505.14112"
        summary: "We introduced IE, a watermarking framework for low-entropy text without origin LLMs."

      - title: "**Tianle Gu**, Kexin Huang, Zongqi Wang, et al. Probing the Robustness of Large Language Models Safety to Latent Perturbations"
        publisher: "ArXiv; Submitted to ACL 2026"
        summary: "We proposed an adversarial attack-and-defense framework to systematically uncover and mitigate latent vulnerabilities in LLM safety."

      - title: "**Tianle Gu**, Kexin Huang, Ruilin Luo, et al. From Evasion to Concealment: Stealthy Knowledge Unlearning for LLMs"
        publisher: "ArXiv; Accepted by ACL 2025 Findings"
        summary: "We proposed a streamlined knowledge-unlearning algorithm that improves forgetting quality while preserving NLU/NLG utility and resilience to MIA."

      - title: "**Tianle Gu**, Kexin Huang, Lingyu Li, et al. From Sparse Decisions to Dense Reasoning: A Multi-attribute Trajectory Paradigm for Multimodal Moderation"
        publisher: "Submitted to ICML 2026"
        summary: "We proposed UniMod, a shift from sparse binary decisions to dense reasoning trajectories for fine-grained multimodal safety moderation."

    Projects:
      - name: "ValuePRM - Core Contributor"
        summary: "[Technical Report](https://arxiv.org/)"
        highlights:
          - "Led ValuePRM training with response-level data to evaluate and verify value-aligned behavior in MLLMs."
          - "Proficient with OpenRLHF for training and fine-tuning both 7B and 70B models."

      - name: "ChatZoo (80+ stars)"
        url: "https://github.com/OpenLMLab/ChatZoo"
        highlights:
          - "Developed ChatZoo, an open-source toolkit for local development and evaluation of multiple LLMs."

      - name: "CoLLiE (400+ stars)"
        url: "https://github.com/OpenMOSS/CoLLiE"
        icon: "https://avatars.githubusercontent.com/u/156300419?s=48&v=4"
        highlights:
          - "Accepted by EMNLP Demo 2023."
          - "Integrated efficient optimization and soft-prompt adaptation for better performance and resource utilization."

      - name: "OpenRT (200+ stars)"
        url: "https://github.com/Carol-gutianle"
        highlights:
          - "Introduced a standard red-teaming framework for quick evaluation."

    Internship:
      - company: Shanghai AI Lab
        position: LLM Distributed Training Engineer (Internship)
        start_date: 2023
        end_date: 2023
        summary: "Supervised by Dr. Hang Yan"

      - company: Shanghai AI Lab
        position: LLM Evaluation and Alignment Researcher (Internship)
        start_date: 2024
        end_date: 2026
        summary: "Supervised by Dr. Yan Teng"

    Notes:
      - bullet: "**Note:** Bold indicates first or co-first author."
